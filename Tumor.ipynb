{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaa4491-05b3-4152-9dec-57adee45bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "base_path = r\"C:/Users/win-10/Desktop/Brain Tumor/\"\n",
    "\n",
    "zips = {\n",
    "    \"data/train\": base_path + \"train-20251210T150534Z-3-001.zip\",\n",
    "    \"data/test\": base_path + \"test-20251210T150533Z-3-001.zip\",\n",
    "    \"data/valid\": base_path + \"valid-20251210T150536Z-3-001.zip\",\n",
    "}\n",
    "\n",
    "for out_dir, zip_file in zips.items():\n",
    "    print(\"Extracting:\", zip_file)\n",
    "\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(zip_file, 'r') as z:\n",
    "        z.extractall(out_dir)\n",
    "\n",
    "print(\"âœ” All ZIP files extracted successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec57f62a-eb95-4515-b0bc-bd9e748ca763",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(base_path + \"drive-download-20251210T150712Z-3-001.zip\", 'r') as z:\n",
    "    z.extractall(base_path + \"drive_download/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ade472-7530-43d4-b95a-aa85c38b82d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts/inspect_dataset.py\n",
    "import os\n",
    "\n",
    "def print_counts(root=\"data\"):\n",
    "    for split in sorted(os.listdir(root)):\n",
    "        split_path = os.path.join(root, split)\n",
    "        if not os.path.isdir(split_path): continue\n",
    "        print(f\"\\n=== {split} ===\")\n",
    "        classes = sorted([d for d in os.listdir(split_path) if os.path.isdir(os.path.join(split_path,d))])\n",
    "        if not classes:\n",
    "            print(\"No class subfolders found in\", split_path)\n",
    "            continue\n",
    "        for cls in classes:\n",
    "            cls_path = os.path.join(split_path, cls)\n",
    "            n = len([f for f in os.listdir(cls_path) if f.lower().endswith(('.jpg','.png','.jpeg'))])\n",
    "            print(f\"{cls}: {n}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print_counts(\"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f95b751-88a5-44a7-86c0-ad597bced5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folders = [\n",
    "    r\"data/train\",\n",
    "    r\"data/test\",\n",
    "    r\"data/valid\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    print(\"\\n=== Inside:\", folder, \"===\")\n",
    "    print(os.listdir(folder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a123a-f394-4317-b3e5-59dff9ee8ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base = r\"data/train\"\n",
    "\n",
    "for item in os.listdir(base):\n",
    "    full = os.path.join(base, item)\n",
    "    if os.path.isdir(full):\n",
    "        print(\"Subfolder:\", full)\n",
    "        print(os.listdir(full)[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d28b8-cba9-4f67-8dca-7ec07227775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "sets = [\"train\", \"test\", \"valid\"]\n",
    "\n",
    "for s in sets:\n",
    "    base = f\"data/{s}\"\n",
    "    inner = os.path.join(base, s)\n",
    "\n",
    "    if not os.path.exists(inner):\n",
    "        continue\n",
    "\n",
    "    for class_name in os.listdir(inner):\n",
    "        src_class = os.path.join(inner, class_name)\n",
    "        dst_class = os.path.join(base, class_name)\n",
    "\n",
    "        if not os.path.isdir(src_class):\n",
    "            continue\n",
    "\n",
    "        # create destination class folder if missing\n",
    "        os.makedirs(dst_class, exist_ok=True)\n",
    "\n",
    "        # move images one by one\n",
    "        for img in os.listdir(src_class):\n",
    "            src_img = os.path.join(src_class, img)\n",
    "            dst_img = os.path.join(dst_class, img)\n",
    "\n",
    "            if not os.path.exists(dst_img):\n",
    "                shutil.move(src_img, dst_img)\n",
    "\n",
    "        # remove empty source class folder\n",
    "        shutil.rmtree(src_class)\n",
    "\n",
    "    # remove now-empty inner folder\n",
    "    shutil.rmtree(inner)\n",
    "\n",
    "print(\"âœ” Dataset folders merged & fixed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6abcd6-c9af-4387-9690-ec285c6fa0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in [\"train\", \"test\", \"valid\"]:\n",
    "    print(f\"\\n=== {s} ===\")\n",
    "    print(os.listdir(f\"data/{s}\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94729a5-ceca-4006-a47c-bd3515320e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# ------------------------------\n",
    "# Data Generators\n",
    "# ------------------------------\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")\n",
    "\n",
    "valid_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_ds = train_datagen.flow_from_directory(\n",
    "    \"data/train\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_ds = valid_test_datagen.flow_from_directory(\n",
    "    \"data/valid\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_ds = valid_test_datagen.flow_from_directory(\n",
    "    \"data/test\",\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca29b97-86f3-4dac-934d-dd1d3bfc61d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224,224,3))\n",
    "base_model.trainable = False  # Freeze weights\n",
    "\n",
    "x = Flatten()(base_model.output)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd828a0-91e0-475b-9c53-2e2a46cdffe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98ef754-1ccc-4d1a-b31a-b52c29a95c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for root, dirs, files in os.walk(\"data\", topdown=True):\n",
    "    print(root, dirs, files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0773ad-f00a-4fcc-930c-bc00e5520e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"data/train\"\n",
    "VALID_DIR = \"data/valid\"\n",
    "TEST_DIR  = \"data/test\"\n",
    "\n",
    "CLASSES = [\"glioma\", \"meningioma\", \"no_tumor\", \"pituitary\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235961ad-393b-4773-9c2b-b098a2862154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "BASE_DIR = \"data/train\"          # original full dataset\n",
    "OUTPUT_DIR = \"data\"              # final keras-ready structure\n",
    "SPLIT_RATIO = 0.2\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "CLASSES = [\"glioma\", \"meningioma\", \"no_tumor\", \"pituitary\"]\n",
    "IMG_EXT = (\".jpg\", \".jpeg\", \".png\")\n",
    "\n",
    "# ===============================\n",
    "# CREATE FOLDERS\n",
    "# ===============================\n",
    "for split in [\"train\", \"valid\"]:\n",
    "    for cls in CLASSES:\n",
    "        os.makedirs(os.path.join(OUTPUT_DIR, split, cls), exist_ok=True)\n",
    "\n",
    "# ===============================\n",
    "# SPLIT DATA\n",
    "# ===============================\n",
    "for cls in CLASSES:\n",
    "    cls_path = os.path.join(BASE_DIR, cls)\n",
    "    images = [\n",
    "        img for img in os.listdir(cls_path)\n",
    "        if img.lower().endswith(IMG_EXT)\n",
    "    ]\n",
    "\n",
    "    train_imgs, valid_imgs = train_test_split(\n",
    "        images,\n",
    "        test_size=SPLIT_RATIO,\n",
    "        random_state=RANDOM_STATE,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    for img in train_imgs:\n",
    "        src = os.path.join(cls_path, img)\n",
    "        dst = os.path.join(OUTPUT_DIR, \"train\", cls, img)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "    for img in valid_imgs:\n",
    "        src = os.path.join(cls_path, img)\n",
    "        dst = os.path.join(OUTPUT_DIR, \"valid\", cls, img)\n",
    "        if not os.path.exists(dst):\n",
    "            shutil.copy(src, dst)\n",
    "\n",
    "    print(f\"{cls}: train={len(train_imgs)}, valid={len(valid_imgs)}\")\n",
    "\n",
    "print(\"\\nâœ” Trainâ€“Validation split completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa898b3-b32b-4a1c-a45e-2d04cd4a2d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=15,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input\n",
    ")\n",
    "\n",
    "train_data = train_datagen.flow_from_directory(\n",
    "    \"data/train\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_data = valid_datagen.flow_from_directory(\n",
    "    \"data/valid\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "# Only if you have test folder\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "    \"data/test\",\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "print(\"Train samples:\", train_data.samples)\n",
    "print(\"Valid samples:\", valid_data.samples)\n",
    "print(\"Test samples:\", test_data.samples)\n",
    "\n",
    "print(\"\\nTrain classes:\", train_data.class_indices)\n",
    "print(\"Valid classes:\", valid_data.class_indices)\n",
    "print(\"Test classes:\", test_data.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af8dfd4-1637-46ec-a859-6accdfc2baaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# =====================================================\n",
    "# PATHS\n",
    "# =====================================================\n",
    "train_path = \"data/train\"\n",
    "valid_path = \"data/valid\"\n",
    "test_path  = \"data/test\"\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# =====================================================\n",
    "# DATA GENERATORS (EFFICIENTNET)\n",
    "# =====================================================\n",
    "train_gen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "valid_gen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    ")\n",
    "\n",
    "train_data = train_gen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "valid_data = valid_gen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# CLASS WEIGHTS  (IMPORTANT FOR CONFIDENCE)\n",
    "# =====================================================\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=np.unique(train_data.classes),\n",
    "    y=train_data.classes\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "print(\"Class Weights:\", class_weights)\n",
    "\n",
    "# =====================================================\n",
    "# MODEL\n",
    "# =====================================================\n",
    "base_model = EfficientNetB0(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "base_model.trainable = False  # Phase 1 freeze\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.4)(x)\n",
    "output = Dense(NUM_CLASSES, activation=\"softmax\")(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "# =====================================================\n",
    "# CALLBACKS\n",
    "# =====================================================\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_model.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "# =====================================================\n",
    "# PHASE 1 â€” TRAIN CLASSIFIER HEAD\n",
    "# =====================================================\n",
    "print(\"\\nðŸ”µ PHASE 1 â€” Training classifier head\\n\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_phase1 = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# PHASE 2 â€” FINE TUNING \n",
    "# =====================================================\n",
    "print(\"\\nðŸŸ£ PHASE 2 â€” Fine-tuning EfficientNet\\n\")\n",
    "\n",
    "for layer in base_model.layers[-100:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "history_phase2 = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=20,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# SAVE LABELS\n",
    "# =====================================================\n",
    "with open(\"class_labels.json\", \"w\") as f:\n",
    "    json.dump(train_data.class_indices, f, indent=4)\n",
    "\n",
    "print(\"âœ… class_labels.json saved\")\n",
    "\n",
    "# =====================================================\n",
    "# TEST EVALUATION\n",
    "# =====================================================\n",
    "loss, acc = model.evaluate(test_data)\n",
    "print(f\"\\n FINAL TEST ACCURACY: {acc*100:.2f}%\")\n",
    "\n",
    "# =====================================================\n",
    "# PLOT TRAINING CURVES\n",
    "# =====================================================\n",
    "plt.figure(figsize=(14,5))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history_phase1.history[\"accuracy\"] + history_phase2.history[\"accuracy\"])\n",
    "plt.plot(history_phase1.history[\"val_accuracy\"] + history_phase2.history[\"val_accuracy\"])\n",
    "plt.title(\"Accuracy\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history_phase1.history[\"loss\"] + history_phase2.history[\"loss\"])\n",
    "plt.plot(history_phase1.history[\"val_loss\"] + history_phase2.history[\"val_loss\"])\n",
    "plt.title(\"Loss\")\n",
    "plt.legend([\"Train\", \"Validation\"])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1444d-2846-4ca1-85bf-6eafc0f3f851",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "y_true = test_data.classes\n",
    "y_pred = np.argmax(model.predict(test_data), axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=list(test_data.class_indices.keys())))\n",
    "print(confusion_matrix(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9852251-0074-4671-96b4-fdf46bc62240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class_labels = train_data.class_indices\n",
    "with open(\"class_labels.json\", \"w\") as f:\n",
    "    json.dump(class_labels, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0c3ac-b8e6-4114-a65f-fc84f2ad340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9794e1-414c-4136-9ab0-118e96bfff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "    # Create a model that maps the input image to the activations\n",
    "    # of the last conv layer and the model predictions\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs],\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    # Compute the gradient of the top predicted class\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    # Gradient of the output neuron with respect to the conv layer\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "\n",
    "    # Mean intensity of the gradient over each feature map\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    # Weight the convolution outputs\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    # Normalize between 0 & 1\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a2e05e-0289-4fff-af89-ccf3906324bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"Test folders:\", os.listdir(\"data/test\"))\n",
    "print(\"Glioma images:\", os.listdir(\"data/test/glioma\")[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e7868a-2c50-428c-a9c6-5628f76ebea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "CLASS = \"glioma\"  # change if needed\n",
    "\n",
    "base_dir = f\"data/test/{CLASS}\"\n",
    "img_name = random.choice(os.listdir(base_dir))\n",
    "img_path = os.path.join(base_dir, img_name)\n",
    "\n",
    "print(\"Using image:\", img_path)\n",
    "\n",
    "img = tf.keras.preprocessing.image.load_img(\n",
    "    img_path, target_size=(224, 224)\n",
    ")\n",
    "\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0) / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207063d3-daa0-4312-8841-5e572db18bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
    "\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        model.inputs,\n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model([img_array])\n",
    "        if pred_index is None:\n",
    "            pred_index = tf.argmax(predictions[0])\n",
    "        class_channel = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(class_channel, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "\n",
    "    heatmap = tf.maximum(heatmap, 0)\n",
    "    heatmap /= tf.reduce_max(heatmap)\n",
    "\n",
    "    return heatmap.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77916cc7-13d8-4174-9c50-807986a79455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gradcam(img_path, heatmap, alpha=0.45):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    import numpy as np\n",
    "\n",
    "    img = Image.open(img_path).resize((224, 224))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap = Image.fromarray(heatmap).resize((224, 224), Image.BILINEAR)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.imshow(heatmap, cmap=\"jet\", alpha=alpha)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bfba65-5f83-45c5-be3f-7f1d96778232",
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap = make_gradcam_heatmap(\n",
    "    img_array,\n",
    "    model,\n",
    "    last_conv_layer_name=\"top_conv\"\n",
    ")\n",
    "\n",
    "display_gradcam(img_path, heatmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bbdfb1-483f-4d31-ba2a-776675a58b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D,\n",
    "    Flatten, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "\n",
    "custom_cnn = Sequential([\n",
    "    Input(shape=(224, 224, 3)),  \n",
    "\n",
    "    Conv2D(32, (3,3), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(64, (3,3), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Conv2D(128, (3,3), activation=\"relu\"),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(),\n",
    "\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation=\"relu\"),\n",
    "    Dense(4, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "custom_cnn.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "custom_cnn.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b98184-145a-40ec-8373-9e7fcc3d20d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cnn.evaluate(test_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8775330d-7fa1-4233-8cdc-ab4d22f7bff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# ================= PATHS =================\n",
    "TRAIN_DIR = \"data/train\"\n",
    "VALID_DIR = \"data/valid\"\n",
    "TEST_DIR = \"data/test\"\n",
    "\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "# ================= DATA GENERATORS =================\n",
    "train_gen = ImageDataGenerator(\n",
    "preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n",
    "rotation_range=20,\n",
    "zoom_range=0.15,\n",
    "horizontal_flip=True\n",
    ")\n",
    "\n",
    "\n",
    "valid_test_gen = ImageDataGenerator(\n",
    "preprocessing_function=tf.keras.applications.efficientnet.preprocess_input\n",
    ")\n",
    "\n",
    "\n",
    "train_data = train_gen.flow_from_directory(TRAIN_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
    "valid_data = valid_test_gen.flow_from_directory(VALID_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\")\n",
    "test_data = valid_test_gen.flow_from_directory(TEST_DIR, target_size=IMG_SIZE, batch_size=BATCH_SIZE, class_mode=\"categorical\", shuffle=False)\n",
    "\n",
    "\n",
    "# ================= MODEL =================\n",
    "base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(224,224,3))\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dropout(0.4)(x)\n",
    "output = Dense(4, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "model = Model(base_model.input, output)\n",
    "\n",
    "\n",
    "model.compile(\n",
    "optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "loss=\"categorical_crossentropy\",\n",
    "metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "\n",
    "callbacks = [\n",
    "EarlyStopping(patience=5, restore_best_weights=True),\n",
    "ModelCheckpoint(\"best_model.keras\", save_best_only=True)\n",
    "]\n",
    "\n",
    "\n",
    "print(\"\\n Training classifier head\")\n",
    "model.fit(train_data, validation_data=valid_data, epochs=10, callbacks=callbacks)\n",
    "\n",
    "\n",
    "print(\"\\n Fineâ€‘tuning model\")\n",
    "\n",
    "with open(\"class_labels.json\", \"w\") as f:\n",
    "    json.dump(train_data.class_indices, f, indent=4)\n",
    "\n",
    "print(\" class_labels.json saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee95370-8069-4e79-9317-f54d4a0a074d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "TRAIN_DIR = \"data/train\"\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "\n",
    "train_data = datagen.flow_from_directory(\n",
    "    TRAIN_DIR,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode=\"categorical\"\n",
    ")\n",
    "\n",
    "print(\"Class indices:\", train_data.class_indices)\n",
    "\n",
    "with open(\"class_labels.json\", \"w\") as f:\n",
    "    json.dump(train_data.class_indices, f, indent=4)\n",
    "\n",
    "print(\"âœ… class_labels.json regenerated successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf250f6-20ed-4b57-b798-028fa668fc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"glioma\": 0,\n",
    "    \"meningioma\": 1,\n",
    "    \"no_tumor\": 2,\n",
    "    \"pituitary\": 3\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0e82c2-4df2-4983-9a3c-bca134038102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
